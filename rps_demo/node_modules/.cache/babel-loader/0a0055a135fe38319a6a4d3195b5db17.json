{"ast":null,"code":"import * as tf from '@tensorflow/tfjs';\nimport { IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS } from './constants';\nexport var getAdvancedModel = function getAdvancedModel() {\n  var model = tf.sequential();\n  model.add(tf.layers.conv2d({\n    inputShape: [IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS],\n    kernelSize: 3,\n    padding: 'same',\n    filters: 32,\n    strides: 1,\n    activation: 'relu',\n    kernelInitializer: 'varianceScaling'\n  })); // Downsample, batchnorm, and dropout!\n\n  model.add(tf.layers.maxPooling2d({\n    poolSize: [2, 2],\n    strides: [2, 2]\n  }));\n  model.add(tf.layers.batchNormalization());\n  model.add(tf.layers.dropout({\n    rate: 0.25\n  }));\n  model.add(tf.layers.conv2d({\n    kernelSize: 3,\n    filters: 64,\n    padding: 'same',\n    strides: 1,\n    activation: 'relu',\n    kernelInitializer: 'varianceScaling'\n  }));\n  model.add(tf.layers.maxPooling2d({\n    poolSize: [2, 2],\n    strides: [2, 2]\n  }));\n  model.add(tf.layers.batchNormalization());\n  model.add(tf.layers.dropout({\n    rate: 0.25\n  })); // Now we flatten the output from the 2D filters into a 1D vector to prepare\n  // it for input into our last layer.\n\n  model.add(tf.layers.flatten()); // complex dense intermediate\n\n  model.add(tf.layers.dense({\n    units: 512,\n    kernelRegularizer: 'l1l2',\n    activation: 'relu'\n  })); // Our last layer is a dense layer which has 3 output units, one for each\n  // output class (i.e. 0, 1, 2).\n\n  var NUM_OUTPUT_CLASSES = 3;\n  model.add(tf.layers.dense({\n    units: NUM_OUTPUT_CLASSES,\n    kernelInitializer: 'varianceScaling',\n    activation: 'softmax'\n  })); // Choose an optimizer, loss function and accuracy metric,\n  // then compile and return the model\n\n  var optimizer = tf.train.adam();\n  model.compile({\n    optimizer: optimizer,\n    loss: 'categoricalCrossentropy',\n    metrics: ['accuracy']\n  });\n  return model;\n}; // The classic MNIST style model\n\nexport var getSimpleModel = function getSimpleModel() {\n  var model = tf.sequential(); // In the first layer of out convolutional neural network we have\n  // to specify the input shape. Then we specify some parameters for\n  // the convolution operation that takes place in this layer.\n\n  model.add(tf.layers.conv2d({\n    inputShape: [IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS],\n    kernelSize: 5,\n    filters: 8,\n    strides: 1,\n    activation: 'relu',\n    kernelInitializer: 'varianceScaling'\n  })); // The MaxPooling layer acts as a sort of downsampling using max values\n  // in a region instead of averaging.\n\n  model.add(tf.layers.maxPooling2d({\n    poolSize: [2, 2],\n    strides: [2, 2]\n  })); // Repeat another conv2d + maxPooling stack.\n  // Note that we have more filters in the convolution.\n\n  model.add(tf.layers.conv2d({\n    kernelSize: 5,\n    filters: 16,\n    strides: 1,\n    activation: 'relu',\n    kernelInitializer: 'varianceScaling'\n  }));\n  model.add(tf.layers.maxPooling2d({\n    poolSize: [2, 2],\n    strides: [2, 2]\n  })); // Now we flatten the output from the 2D filters into a 1D vector to prepare\n  // it for input into our last layer. This is common practice when feeding\n  // higher dimensional data to a final classification output layer.\n\n  model.add(tf.layers.flatten()); // Our last layer is a dense layer which has 3 output units, one for each\n  // output class (i.e. 0, 1, 2).\n\n  var NUM_OUTPUT_CLASSES = 3;\n  model.add(tf.layers.dense({\n    units: NUM_OUTPUT_CLASSES,\n    kernelInitializer: 'varianceScaling',\n    activation: 'softmax'\n  })); // Choose an optimizer, loss function and accuracy metric,\n  // then compile and return the model\n\n  var optimizer = tf.train.adam();\n  model.compile({\n    optimizer: optimizer,\n    loss: 'categoricalCrossentropy',\n    metrics: ['accuracy']\n  });\n  return model;\n};","map":{"version":3,"sources":["C:/Users/jowil/Downloads/rps_tfjs_demo-master/rps_tfjs_demo-master - Copy/src/tfjs/models.js"],"names":["tf","IMAGE_WIDTH","IMAGE_HEIGHT","NUM_CHANNELS","getAdvancedModel","model","sequential","add","layers","conv2d","inputShape","kernelSize","padding","filters","strides","activation","kernelInitializer","maxPooling2d","poolSize","batchNormalization","dropout","rate","flatten","dense","units","kernelRegularizer","NUM_OUTPUT_CLASSES","optimizer","train","adam","compile","loss","metrics","getSimpleModel"],"mappings":"AAAA,OAAO,KAAKA,EAAZ,MAAoB,kBAApB;AACA,SAASC,WAAT,EAAsBC,YAAtB,EAAoCC,YAApC,QAAwD,aAAxD;AAEA,OAAO,IAAMC,gBAAgB,GAAG,SAAnBA,gBAAmB,GAAM;AACpC,MAAMC,KAAK,GAAGL,EAAE,CAACM,UAAH,EAAd;AAEAD,EAAAA,KAAK,CAACE,GAAN,CACEP,EAAE,CAACQ,MAAH,CAAUC,MAAV,CAAiB;AACfC,IAAAA,UAAU,EAAE,CAACT,WAAD,EAAcC,YAAd,EAA4BC,YAA5B,CADG;AAEfQ,IAAAA,UAAU,EAAE,CAFG;AAGfC,IAAAA,OAAO,EAAE,MAHM;AAIfC,IAAAA,OAAO,EAAE,EAJM;AAKfC,IAAAA,OAAO,EAAE,CALM;AAMfC,IAAAA,UAAU,EAAE,MANG;AAOfC,IAAAA,iBAAiB,EAAE;AAPJ,GAAjB,CADF,EAHoC,CAepC;;AACAX,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUS,YAAV,CAAuB;AAAEC,IAAAA,QAAQ,EAAE,CAAC,CAAD,EAAI,CAAJ,CAAZ;AAAoBJ,IAAAA,OAAO,EAAE,CAAC,CAAD,EAAI,CAAJ;AAA7B,GAAvB,CAAV;AACAT,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUW,kBAAV,EAAV;AACAd,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUY,OAAV,CAAkB;AAAEC,IAAAA,IAAI,EAAE;AAAR,GAAlB,CAAV;AAEAhB,EAAAA,KAAK,CAACE,GAAN,CACEP,EAAE,CAACQ,MAAH,CAAUC,MAAV,CAAiB;AACfE,IAAAA,UAAU,EAAE,CADG;AAEfE,IAAAA,OAAO,EAAE,EAFM;AAGfD,IAAAA,OAAO,EAAE,MAHM;AAIfE,IAAAA,OAAO,EAAE,CAJM;AAKfC,IAAAA,UAAU,EAAE,MALG;AAMfC,IAAAA,iBAAiB,EAAE;AANJ,GAAjB,CADF;AAUAX,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUS,YAAV,CAAuB;AAAEC,IAAAA,QAAQ,EAAE,CAAC,CAAD,EAAI,CAAJ,CAAZ;AAAoBJ,IAAAA,OAAO,EAAE,CAAC,CAAD,EAAI,CAAJ;AAA7B,GAAvB,CAAV;AACAT,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUW,kBAAV,EAAV;AACAd,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUY,OAAV,CAAkB;AAAEC,IAAAA,IAAI,EAAE;AAAR,GAAlB,CAAV,EAhCoC,CAkCpC;AACA;;AACAhB,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUc,OAAV,EAAV,EApCoC,CAsCpC;;AACAjB,EAAAA,KAAK,CAACE,GAAN,CACEP,EAAE,CAACQ,MAAH,CAAUe,KAAV,CAAgB;AACdC,IAAAA,KAAK,EAAE,GADO;AAEdC,IAAAA,iBAAiB,EAAE,MAFL;AAGdV,IAAAA,UAAU,EAAE;AAHE,GAAhB,CADF,EAvCoC,CA+CpC;AACA;;AACA,MAAMW,kBAAkB,GAAG,CAA3B;AACArB,EAAAA,KAAK,CAACE,GAAN,CACEP,EAAE,CAACQ,MAAH,CAAUe,KAAV,CAAgB;AACdC,IAAAA,KAAK,EAAEE,kBADO;AAEdV,IAAAA,iBAAiB,EAAE,iBAFL;AAGdD,IAAAA,UAAU,EAAE;AAHE,GAAhB,CADF,EAlDoC,CA0DpC;AACA;;AACA,MAAMY,SAAS,GAAG3B,EAAE,CAAC4B,KAAH,CAASC,IAAT,EAAlB;AACAxB,EAAAA,KAAK,CAACyB,OAAN,CAAc;AACZH,IAAAA,SAAS,EAAEA,SADC;AAEZI,IAAAA,IAAI,EAAE,yBAFM;AAGZC,IAAAA,OAAO,EAAE,CAAC,UAAD;AAHG,GAAd;AAMA,SAAO3B,KAAP;AACD,CApEM,C,CAsEP;;AACA,OAAO,IAAM4B,cAAc,GAAG,SAAjBA,cAAiB,GAAM;AAClC,MAAM5B,KAAK,GAAGL,EAAE,CAACM,UAAH,EAAd,CADkC,CAGlC;AACA;AACA;;AACAD,EAAAA,KAAK,CAACE,GAAN,CACEP,EAAE,CAACQ,MAAH,CAAUC,MAAV,CAAiB;AACfC,IAAAA,UAAU,EAAE,CAACT,WAAD,EAAcC,YAAd,EAA4BC,YAA5B,CADG;AAEfQ,IAAAA,UAAU,EAAE,CAFG;AAGfE,IAAAA,OAAO,EAAE,CAHM;AAIfC,IAAAA,OAAO,EAAE,CAJM;AAKfC,IAAAA,UAAU,EAAE,MALG;AAMfC,IAAAA,iBAAiB,EAAE;AANJ,GAAjB,CADF,EANkC,CAiBlC;AACA;;AACAX,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUS,YAAV,CAAuB;AAAEC,IAAAA,QAAQ,EAAE,CAAC,CAAD,EAAI,CAAJ,CAAZ;AAAoBJ,IAAAA,OAAO,EAAE,CAAC,CAAD,EAAI,CAAJ;AAA7B,GAAvB,CAAV,EAnBkC,CAqBlC;AACA;;AACAT,EAAAA,KAAK,CAACE,GAAN,CACEP,EAAE,CAACQ,MAAH,CAAUC,MAAV,CAAiB;AACfE,IAAAA,UAAU,EAAE,CADG;AAEfE,IAAAA,OAAO,EAAE,EAFM;AAGfC,IAAAA,OAAO,EAAE,CAHM;AAIfC,IAAAA,UAAU,EAAE,MAJG;AAKfC,IAAAA,iBAAiB,EAAE;AALJ,GAAjB,CADF;AASAX,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUS,YAAV,CAAuB;AAAEC,IAAAA,QAAQ,EAAE,CAAC,CAAD,EAAI,CAAJ,CAAZ;AAAoBJ,IAAAA,OAAO,EAAE,CAAC,CAAD,EAAI,CAAJ;AAA7B,GAAvB,CAAV,EAhCkC,CAkClC;AACA;AACA;;AACAT,EAAAA,KAAK,CAACE,GAAN,CAAUP,EAAE,CAACQ,MAAH,CAAUc,OAAV,EAAV,EArCkC,CAuClC;AACA;;AACA,MAAMI,kBAAkB,GAAG,CAA3B;AACArB,EAAAA,KAAK,CAACE,GAAN,CACEP,EAAE,CAACQ,MAAH,CAAUe,KAAV,CAAgB;AACdC,IAAAA,KAAK,EAAEE,kBADO;AAEdV,IAAAA,iBAAiB,EAAE,iBAFL;AAGdD,IAAAA,UAAU,EAAE;AAHE,GAAhB,CADF,EA1CkC,CAkDlC;AACA;;AACA,MAAMY,SAAS,GAAG3B,EAAE,CAAC4B,KAAH,CAASC,IAAT,EAAlB;AACAxB,EAAAA,KAAK,CAACyB,OAAN,CAAc;AACZH,IAAAA,SAAS,EAAEA,SADC;AAEZI,IAAAA,IAAI,EAAE,yBAFM;AAGZC,IAAAA,OAAO,EAAE,CAAC,UAAD;AAHG,GAAd;AAMA,SAAO3B,KAAP;AACD,CA5DM","sourcesContent":["import * as tf from '@tensorflow/tfjs'\nimport { IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS } from './constants'\n\nexport const getAdvancedModel = () => {\n  const model = tf.sequential()\n\n  model.add(\n    tf.layers.conv2d({\n      inputShape: [IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS],\n      kernelSize: 3,\n      padding: 'same',\n      filters: 32,\n      strides: 1,\n      activation: 'relu',\n      kernelInitializer: 'varianceScaling'\n    })\n  )\n\n  // Downsample, batchnorm, and dropout!\n  model.add(tf.layers.maxPooling2d({ poolSize: [2, 2], strides: [2, 2] }))\n  model.add(tf.layers.batchNormalization())\n  model.add(tf.layers.dropout({ rate: 0.25 }))\n\n  model.add(\n    tf.layers.conv2d({\n      kernelSize: 3,\n      filters: 64,\n      padding: 'same',\n      strides: 1,\n      activation: 'relu',\n      kernelInitializer: 'varianceScaling'\n    })\n  )\n  model.add(tf.layers.maxPooling2d({ poolSize: [2, 2], strides: [2, 2] }))\n  model.add(tf.layers.batchNormalization())\n  model.add(tf.layers.dropout({ rate: 0.25 }))\n\n  // Now we flatten the output from the 2D filters into a 1D vector to prepare\n  // it for input into our last layer.\n  model.add(tf.layers.flatten())\n\n  // complex dense intermediate\n  model.add(\n    tf.layers.dense({\n      units: 512,\n      kernelRegularizer: 'l1l2',\n      activation: 'relu'\n    })\n  )\n\n  // Our last layer is a dense layer which has 3 output units, one for each\n  // output class (i.e. 0, 1, 2).\n  const NUM_OUTPUT_CLASSES = 3\n  model.add(\n    tf.layers.dense({\n      units: NUM_OUTPUT_CLASSES,\n      kernelInitializer: 'varianceScaling',\n      activation: 'softmax'\n    })\n  )\n\n  // Choose an optimizer, loss function and accuracy metric,\n  // then compile and return the model\n  const optimizer = tf.train.adam()\n  model.compile({\n    optimizer: optimizer,\n    loss: 'categoricalCrossentropy',\n    metrics: ['accuracy']\n  })\n\n  return model\n}\n\n// The classic MNIST style model\nexport const getSimpleModel = () => {\n  const model = tf.sequential()\n\n  // In the first layer of out convolutional neural network we have\n  // to specify the input shape. Then we specify some parameters for\n  // the convolution operation that takes place in this layer.\n  model.add(\n    tf.layers.conv2d({\n      inputShape: [IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS],\n      kernelSize: 5,\n      filters: 8,\n      strides: 1,\n      activation: 'relu',\n      kernelInitializer: 'varianceScaling'\n    })\n  )\n\n  // The MaxPooling layer acts as a sort of downsampling using max values\n  // in a region instead of averaging.\n  model.add(tf.layers.maxPooling2d({ poolSize: [2, 2], strides: [2, 2] }))\n\n  // Repeat another conv2d + maxPooling stack.\n  // Note that we have more filters in the convolution.\n  model.add(\n    tf.layers.conv2d({\n      kernelSize: 5,\n      filters: 16,\n      strides: 1,\n      activation: 'relu',\n      kernelInitializer: 'varianceScaling'\n    })\n  )\n  model.add(tf.layers.maxPooling2d({ poolSize: [2, 2], strides: [2, 2] }))\n\n  // Now we flatten the output from the 2D filters into a 1D vector to prepare\n  // it for input into our last layer. This is common practice when feeding\n  // higher dimensional data to a final classification output layer.\n  model.add(tf.layers.flatten())\n\n  // Our last layer is a dense layer which has 3 output units, one for each\n  // output class (i.e. 0, 1, 2).\n  const NUM_OUTPUT_CLASSES = 3\n  model.add(\n    tf.layers.dense({\n      units: NUM_OUTPUT_CLASSES,\n      kernelInitializer: 'varianceScaling',\n      activation: 'softmax'\n    })\n  )\n\n  // Choose an optimizer, loss function and accuracy metric,\n  // then compile and return the model\n  const optimizer = tf.train.adam()\n  model.compile({\n    optimizer: optimizer,\n    loss: 'categoricalCrossentropy',\n    metrics: ['accuracy']\n  })\n\n  return model\n}\n"]},"metadata":{},"sourceType":"module"}